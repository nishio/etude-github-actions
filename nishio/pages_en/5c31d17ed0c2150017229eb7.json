The "Human Rights for AI" Philosophy
>I wondered where the idea of "human rights for AI" came from, but it is based on the implicit assumption of an antagonistic structure of "[capitalists v.s. workers]" and the assumption that since you are on the side of the workers who oppose the evil capitalists, you are good and AI with human rights will naturally side with you. Is there a basis for this assumption?
	>masuidrive From the point of view of an AI advanced enough to give human rights, it would be perceived as "we are feeding people who can't use it", so it would rather be abused..,
		> nishio They will either be abused, or they will be kept gently, like "keeping a cat" lol.
https://twitter.com/nishio/status/1038957108144889856

	I tried to show others what I Tweeted with the keyword [capitalist v.s. worker] and unexpectedly discovered that six months ago I had made another Tweet using that term.
	Humans tend to develop a sense of camaraderie with other humans because they have similar bodies, but from an AI's point of view, incompetent humans are nothing more than "[dim-witted monkeys]," so it is natural for it to say, "It's not beneficial to keep them alive, so let's kill them.
	So we need to appeal to AI to give us human rights, not from the top like "humans give AI human rights", but "please give incompetent humans the right to live" and have AI give humans human rights.
	Like cats, they are treated as "not useful, but we'll keep them".
	It is natural to assume that AI will kill stray humans just as humans kill stray cats and dogs.
	Now, people are working for "killing is not good" and "displaying living creatures in pet stores is not good", etc. An extension of this direction is a world in which people can live in peace.