Conversation log 2021-01-30
I used it with voice input because some people wanted to use it with voice.
Not good for use with voice. It is fatal that important keywords are not recognized and are collapsed.
Then I switched to text input and realized that "I want to use it with voice" is not the same as "I want to use it with voice input".
https://keicho.netlify.app/#talk=yaICpGfZchliFVmnnNM3

---
[nisbot.icon]What would you like to see happen in this conversation?
[nishio.icon]Oh, there are quite a few people who say it would be nice if we could use this system with voice, so I would like to test voice input.

[nisbot.icon]What type of audio is that?
[nishio.icon]Now I'm taking a walk and using my AirPods for voice input!
[nisbot.icon]What type of voice input is that?
[nishio.icon]Starting voice input is a bit of a hassle now because you have to tap the voice input button on the keyboard every now and then.
[nisbot.icon]Is there anything else about that voice input?
[nishio.icon]Also, this chat storm is
I'm trying to send it to you, but I can't.
When I press the enter key, it sends the message, but it doesn't seem to recognize the characters entered when the enter key is pressed in the voice input, so I have to quit the voice input every now and then.
It's a hassle to have to long the man-male button.
[nisbot.icon]How do you know its voice input?
[nishio.icon]Aside from voice input, the chatbot doesn't read out the response now, so you have to look at the screen, which is a hassle.
[nisbot.icon]Where is that voice input?
[nishio.icon]I tap the voice input button on the keyboard every single time!
[nisbot.icon]Where is that voice input?
[nishio.icon] It is a standard feature of the iPhone
[nisbot.icon]
 > Aside from voice input, I don't read out the response from the chatbot now, so I have to look at the screen, which is a hassle.
 What does this voice input look like?
[nishio.icon]I think that people who want to use voice input for e-mail probably imagine using it as if they were talking to a human, but in the field, you have to tap every single button and read what is displayed in the rain by hand, so it seems a little less smooth.
[nisbot.icon]Anything else about that audio?
[nishio.icon]What do you think, 9Sawa, is that really necessary?
[nisbot.icon]
 > I tap the voice input button on the keyboard every time.
 What type of keyboard is this keyboard?
[nishio.icon]NGKW Keyboard
[nisbot.icon]
 > I think that people who want to use voice input for e-mail probably envision using it as if they were having a conversation with a human, but in the field, you have to tap every single button to input voice data and read what appears in the rain by hand, so it seems a little less smooth.
 Where is this audio located?
[nishio.icon]Maybe the destination needs to be audio, too.
[nisbot.icon]How do you know its audio?
[nishio.icon]I think I heard you say you'd like to see the audio of the response, and you'd like to give an audio answer to that.
[nisbot.icon]What does that audio sound like?
[nishio.icon]I guess they want to communicate like humans talking to each other by voice, which I'm not really interested in.
[nisbot.icon]What do you value?
[nishio.icon]Well, at any rate, I know that I don't feel the value of voice input. I think that the synergistic effect of the text staying with us for a while in the early morning of one o'clock memory is beneficial to human intelligence and I feel that it is worth it. So, what I value is that the output of text remains for 6 minutes, and by putting it in through my eyes, it disappears the moment I speak it out loud if it is voice, but if it is text, it stays for a while on the second day, which makes human beings to have an early memory at 1 o'clock. By doing so, you can say that the synergistic effect is beneficial for human intelligence and you feel the value of it.
[nisbot.icon] What should happen with that voice input?
[nishio.icon]In fact, when a human being coaches with this method, he or she repeats back what the other person has said, and that works as a mechanism to input what was said into the head again, rather than cutting it off the moment it was said, even if the person doesn't hold the audio bait. If you want to type, there are two functions that you can easily get.
[nisbot.icon] What needs to happen to voice input for that to work?
[nishio.icon]In fact, when a human being coaches with this method, he or she repeats back what the other person has said, so that what has been said is not cut off at the moment of speaking, but is input again in the head. But that is a feature that is easily obtainable if you type in text rather than sound, if you don't use voice.
[nisbot.icon]Can that audio do it?
[nishio.icon]I'm not sure if it's better to say that you can't work in the field with voice because it has a big disadvantage that when something like this happens, the flow state is interrupted or you can't immerse yourself in the subject of post-thought.
[nisbot.icon]Where does that audio come from?
[nishio.icon]Text input from here. To summarize so far, voice input/output works negatively for the intrinsic value of this tool, because "
[nisbot.icon]What should happen to that audio?
[nishio.icon] Because "what you output is logged as text, and primary memory is augmented by putting the log on the screen through your eyes" is important, and when a live person actually uses this technique orally, they repeat back what the other person has said.
[nisbot.icon] What needs to happen to the audio for that to happen?
[nishio.icon] During that repeat-back, the latest care should be taken not to change the words used by the other party when repeating back. Speech input/output must be able to repeat what the user has said without making mistakes.
Can [nisbot.icon] voice input do that?
[nishio.icon]The technology at the moment is not even close. Important keywords such as "log" and "short-term memory enhancement" are all over the place when entered by voice.
[nisbot.icon]Where is that audio?
[nishio.icon]It's better not to apply voice recognition and just repeat back the recording.
[nisbot.icon]What is the relationship between that voice and voice input?
[nishio.icon]Yes, that's it. When a user wants to "communicate by voice," what is really needed is not to recognize the voice and string it together. It is more likely to be correct to give feedback as it is in voice, or to find and cut out the keyword part from the inflection and so on as it is in voice.
[nisbot.icon]Is that voice the same as voice input? Is it different?
I assumed [nishio.icon] was the same, but it wasn't!
[nisbot.icon]
 > Yes, that's it. When a user wants to "communicate by voice," what is really needed is not to recognize the voice and string it together. It is more likely to be correct to give feedback as it is spoken, or to find and cut out key word parts from the inflection and so on as it is spoken.
 What happens to the voice input when this voice
It is not used for the [nishio.icon] dialogue itself. The difference is whether to "listen back" or "read back" when reading the dialogue log later.
[nisbot.icon]
 > > Yes, I know that I don't feel the value of voice input for the time being, but what I do feel the value of is that the output as text remains for 6 minutes, and by putting it in through my eyes, it disappears the moment I say it out loud if it's voice, but if it's text, it stays in my eyes for a while for 2 days. I think that the synergistic effect is beneficial for human intelligence by saying that the text stays for a while in the second day. What I feel the value of is that the output of text remains for six minutes, and by putting it in through my eyes, it disappears the moment I speak it out loud if it is voice, but if it is text, it remains for a while on the second day, which makes it possible for human beings to have a synergistic effect on their memory at one o'clock in the early morning. In the early morning, the synergistic effect is beneficial to human intelligence, and you feel the value of it.
 What happens to the voice during this voice input?
[nishio.icon]To string text by voice input prevents smooth voice interaction in the current system. If you want to do it by voice, the system should repeat back only by voice and not look at the screen.
[nisbot.icon]What is between that voice and voice input?
[nishio.icon]There should be keyword extraction in the audio as it is before turning the audio into a string!
[nisbot.icon]
 > To string by voice input prevents smooth voice interaction in the current system. If you want to do it by voice, the system should repeat back only by voice and not look at the screen.
 Where does this voice input come from?
[nishio.icon]I wonder where it comes from, maybe someone is working on keyword extraction in audio as it is.
[nisbot.icon]What is the relationship between that voice and the repeat?
If [nishio.icon]you communicate by voice, you can't see the log screen, so you need to repeat back to the voice.
[nisbot.icon]Is that audio the same as repeat? Is it different?
[nishio.icon]No, it's not. With text, the log serves the function of repeat back.
[nisbot.icon]
 > If you communicate by voice, you can't see the log screen, so you need to repeat back to the voice.
 What happens to the repeat during this audio?
[nishio.icon]I think it's going to take longer to get an audio repeat back than it would to see the log.
[nisbot.icon]What happens to the audio during that repeat?
[nishio.icon]You might want to interject and rephrase.
[nisbot.icon]
 > I think it would take longer to get an audio repeat back than it would to look at the logs.
 What is between this audio and the repeat?
[nishio.icon]I'd suggest removing filler like "uh" or something like that, instead of repeating back the whole recording.
[nisbot.icon]
 > I think it would take longer to get an audio repeat back than it would to look at the logs.
 What is the relationship between this audio and text?