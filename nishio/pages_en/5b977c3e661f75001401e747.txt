Skip-Gram
Skip-Gram is, in essence, [AutoEncoder] input that is not the same word but surrounding words
	If you use a word [1-of-K vector] as input, there is not much [dimensionality compression] if you use the same word as input.
 What would happen if we were forced to do it? I wonder if it would be in the middle tier, chosen in order of frequency of occurrence.