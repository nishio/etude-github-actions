Natural Language Processing with Deep Learning
[https://gyazo.com/bb45d0ef28f156cfa28d7b75ae6a44e5]
	[Amazon https://amzn.to/2WIKeLd]

https://www.kspub.co.jp/book/detail/1529243.html

Chapter 1: [Natural Language Processing] Approach
1.1 伝統的な自然言語処理
1.2 Expectations for [deep learning
1.3 Characteristics of text data
1.4 Expansion into other fields

Chapter 2: Fundamentals of Neural Networks
2.1 Supervised learning
2.2 Forward Propagating Neural Networks
2.3 活性化関数
2.4 勾配法
2.5 誤差逆伝播法
2.6 Recurrent Neural Networks #RNN
2.7 Gated Recurrent Neural Networks
	[LSTM]
 [GRU]
2.8 Tree-structured recurrent neural nets
	[recursive neural networks] = [Tree-RNN]
2.9 Convolutional Neural Networks #CNN

Chapter 3: Fundamentals of Deep Learning in Linguistic Processing
3.1 Preparation: Bridging the world of symbols and the world of vectors
3.2 Language Model
3.3 [分散表現]
	[LBL model] [対数双線形モデル]
 [word2vec] [skip-gram] [CBoW]
3.4 Series transformation model
	[seq2seq]

第4章　言語処理特有の深層学習の発展
4.1 [注意機構]
4.2 [Memory network].
4.3 出力層の高速化

第5章　応用
5.1 機械翻訳
5.2 文書要約
5.3 対話
5.4 質問応答

Chapter 6: Techniques to Improve Generalization Performance
6.1 汎化誤差の分解
6.2 推定誤差低減に効く手法
6.3 最適化誤差低減に効く手法
6.4 Super-parameter selection

第7章　実装
7.1 GPUとGPGPU
7.2 Minibatching in RNNs
7.3 無作為抽出
7.4 Reducing Memory Usage
7.5 誤差逆伝播法の実装
