Cookpad + BERT
Cookpad's experience with self-training [BERT] with in-house data.
[BERT with SentencePiece to learn Japanese-specific pre-trained models and solve tasks based on them - Cookpad Developer Blog https://techlife.cookpad.com/entry/2018/12/04/093000]

	>BERT's multilingual model is not suitable for handling Japanese, so use [SentencePiece].
		Related [Why Google Bert's tokenizer can muddy the waters].
 > Use Cookpad cooking instructions text (approx. 16 million sentences) for pre-training
 > Learning takes about 3.5 days on a p3.2xlarge instance
		p3.2xlarge is 3USD/hour, so about 25,000.
