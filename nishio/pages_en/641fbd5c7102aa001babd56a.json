The talent to feel respect for things.
>[shanegJP https://twitter.com/shanegJP/status/1639820629062070272] The "spell" used in all of ChatGPT, GPT-4, and ChatGPT plugins, and the most memorable language model paper of 2022 was found by @Matsuo_Lab Kojima-kun and Iwasawa-san @yusuke_iwasawa_ of Matsuo Lab. I helped with the paper and it was a great find.
> 
> How could the Japanese find this... (next)
> >jaguring1: ChatGPTを賢くする呪文
> 
> It talks about "Let's think step by step".
> 
> Takeshi Kojima, the discoverer of this spell.
> "I suspect that both intuitive and logical ways of thinking to answer questions have been acquired in the large-scale language model."
> https://nikkei.com/article/DGXZQOUC22BVO0S3A320C2000000/…

>[shanegJP https://twitter.com/shanegJP/status/1639820630597210112] My theory is that the Japanese have the most talent to be impressed by AI. The talent to feel "human (like) emotion and respect" for "things" ([Shinto], from 8 million gods?) is the best in the ChatGPT era. I am looking forward to it.

>[shanegJP https://twitter.com/shanegJP/status/1639822013496971265] Just ask "things" (AI, GPT, ChatGPT) "like people". It's commonplace now, but I don't think Americans or anyone else had this idea. Also this:
> >shanegJP: When I toured a Japanese robot lab 10 years ago, a phrase stuck in my memory: "Japan couldn't make the Roomba."
> 
> But it was only because I wanted to make Doraemon."
> 
> I think deep learning is the same thing, ImageNet, BERT, are just machine learning. Japan has only been looking at general-purpose artificial intelligence for 40 years. That's why I think ChatGPT has stuck so strongly.

>[shanegJP https://twitter.com/shanegJP/status/1639828671354802178] Not surprisingly, it is also cited and used in the GPT-4 paper.
> 
> GPT-4論文： https://cdn.openai.com/papers/gpt-4.pdf… 小島君の論文：https://arxiv.org/abs/2205.11916
> [https://pbs.twimg.com/media/FsHW5MyaAAAyWCd?format=jpg&name=medium#.png]
