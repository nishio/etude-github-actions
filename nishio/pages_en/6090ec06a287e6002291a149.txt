Hatena2011-02-17
code:hatena
 <body>
 *1297902929* What is a random variable?
 http://homepage1.nifty.com/herumi/diary/1102.html#16
 >>
 Nishio said he's not sure if the random variable is a variable or a mapping.
 <<
 
 I thought it was more like "I understand that the random variable is a function of Ω→R, but what is the difference between that and a probability distribution? Let me summarize what I understood from what I was taught.
 
 - Some subsets of the set of continuous densities (e.g., [0, 1]) are such that the measure (length, area, ...) cannot be defined for some of the subsets of a continuous set of concentrations (e.g., [0, 1]).
 -- Even the <a href='http://ja.wikipedia.org/wiki/%E3%82%AB%E3%83%B3%E3%83%88%E3%83%BC %E3%83%AB%E9%9B%86%E5%90%88'>Cantor set</a>, which is a continuous concentration but of length 0, can be defined as " length 0" and is able to define a length. A set even creepier than this. Because of such sets <a href='http://ja.wikipedia.org/wiki/%E3%83%90%E3%83%8A%E3%83%83%E3%83%8F %EF%BC%9D%E3%82%BF%E3%83%AB%E3%82%B9%E3%82%AD %E3%83%BC%E3%81%AE%E3%83%91 %E3%83%A9%E3%83%89%E3%83%83%E3%82%AF%E3%82%B9'>The Banach-Tarski paradox</a> occurs
 - So instead of an unlimited "set of all subsets," I'd like to come up with a set that excludes those creeps.
 
 I guess that's what you mean. I can't necessarily make a constructive mapping in more than 2 dimensions, but I can show that it exists, so that's good enough. It seems to be.
 
 So, if a programmer tries to think strictly about the type, he/she will get the error "X is compared to 0, so it must be a real value, and... what, the argument of P is not an event? You mean "the event that X < 0"? Is there something like "P(X)" over here? What the heck is this ？？？？? I'll give up thinking it's an abbreviation for short-coding!
 
 *1297949075* mind map diary 4
 Why is it that after I take a picture of a mind map with my iPhone and send it to Hatena Diary, the one on my blog is not updated when I rotate the one with the wrong orientation in Hatena Photo Life? Is there something wrong with the cache?
 
 I'll try to rotate it on the iPhone side next time. I also wonder how to take a good picture without making it look like a trapezoid. I could take a picture from the front, but then the shadow would show up in the picture. I guess I need to work on the angle with the lighting.
 
 Well, I have tried to write a clean copy, but there are still a lot of mistakes. Or should I say, I noticed the mistakes because I have tried to write it out.
 
 It was a mistake to assign the green square to the covariance matrix because the inverse of the matrix of the partitioned covariance matrix does not match the partitioned precision matrix. This would not represent the inverse of the divided precision matrix. I tried to introduce a different notation in a hurry, but thinking calmly, there is no need for a special notation because the covariance matrix does not appear until the end of the process.
 
 Also, the derivation of the conditional distribution on the right side should have been done before the decomposition of the block. The flow is not straightforward.
 
 One new finding I noticed is that when deriving the conditional distribution, PRML fixed xb, but it is better to fix xa here. Then, when deriving the next marginal distribution, the conditional distribution obtained earlier will be used. In other words, in either case, the second-order term and the first-order term of xb will have a common phase to sort out, so the calculation results can be reused. I realized this after I drew the mind map, so it is not included in this figure. I'll have to do it again.
 
 f:id:nishiohirokazu:20110217154629j:image
 
 The idea of "distinguishing the appearance of ab and ba from that of aa and bb" that I mentioned yesterday converged in this way: it is correct in terms of the amount of information that the matrix has the information about whether xa or xb, so there is no need to write it on the x side, but in reality it is difficult to find the first order term of xa. It's hard to find the "which is the first order term of xa". But in reality, it is difficult to find the first order term of xa. So I extended the horizontal bar to the top and bottom of x, and it became easier to understand that "the red line on the top is xa and the red line on the bottom is xb".
 
 f:id:nishiohirokazu:20110217190109j:image
 
 The result of the calculation looks like this
 
 f:id:nishiohirokazu:20110217190148j:image
 
 And since all I do is queue, I wrote down the contents of the introductory Git course. I'm having a hard time with the "Describe Git as a picture" thing.
 
 f:id:nishiohirokazu:20110217190008j:image
 
 I did my best to draw the commands because they are important, but while I was drawing, I started to wonder if reset HEAD^ and rebase are not operations on the repository. The index is drawn as a box full of changesets, but it also has information about which commit object the current commit object is a child of, and reset HEAD^ and rebase rewrite that information, don't they? I was thinking, "What is the point of resetting HEAD^ and rebase? I thought, "I've never used these commands before. I have never used these commands, so I will check them later.
 
 f:id:nishiohirokazu:20110217190025j:image
 </body>
 <comments>
 <comment>
 <username>Zo</username>.
 <body>P(X < 0) is exactly syntax sugar, which is a shorthand notation for P({ω∈Ω|X(ω) < 0}). Well, to begin with, X^{-1} itself is syntax sugar (is overloading closer to the image?). It can be used for inverse functions, or to represent a range of values. <br><br><br>As for the inverse function, it can be used for a range of definitions corresponding to a range of values. <BR><BR><BR>Well, actually, probability theory is mathematically difficult to do properly, but in actual use, you don't need to be aware of the complications. <BR><BR>I'll give you a little tip: <BR>Probability -> length, area, volume, mass, etc.<BR>Probability density -> density<BR>Probability variable -> function<BR>Expectation value -> integral<BR>It's easy to get the picture (in fact, mathematically, they are the same thing). <BR><BR>For example, if we place a non-uniform object in a gravitational field, the gravity acting on this object is the gravitational field integrated over the entire region where the object exists, weighted by the mass per unit volume (= density). <BR><BR>Similarly, taking the expected value of a random variable is the value of the random variable integrated over the entire probability space, weighted by the probability per sample (= probability density), is it not? <br><br><br>If you think of the analogy as such, you will soon be able to visualize the complicated topics of probability theory with surprising ease. </body>
 <timestamp>1297956664</timestamp>
 </comment>
 <comment>
 <username>skrb</username>
 <body>If you use CamScanner or any other application that can correct the trapezoidal shape, you can turn the trapezoidal image back into a rectangle. </body>
 <timestamp>1297995214</timestamp>
 </comment>
 </comments>

[Hatena Diary 2011-02-17 https://nishiohirokazu.hatenadiary.org/archive/2011/02/17]