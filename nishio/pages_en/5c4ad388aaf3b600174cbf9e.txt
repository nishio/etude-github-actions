Always in the shadows.
[https://gyazo.com/94771e8fc3c1fdae46962ed3d5b9fb9a]

[Tomoya Tachikawa] pointed out in response to [Pyramid of Knowledge
>Vector -> Linear Algebra -> Machine Learning I think, but after learning machine learning without understanding the translation, I have a better understanding of linear algebra.

In the model written in [The principle that the learning curve is an S-curve
	Acquiring abstract knowledge makes it easier to acquire the concrete knowledge that lies beneath it.
written as

Is this true?
Is the act of "learning machine learning without understanding the translation" really acquiring knowledge directly at a higher level of abstraction?
When you are learning without understanding, are you really learning anything near the top of the pyramid?
Rather, we are learning about shadows on the ground, aren't we?

The tower casts a flat shadow on the ground.
High abstractions have information that corresponds to concrete layers of lower abstraction.
By learning this less abstract information in a way that we don't understand, we accumulate knowledge that "A and B are connected.
When you eventually understand A, A, which was placed on the ground, is lifted higher, and B and C are also pulled upward

