Is it essential that the query be in natural language?
>[dmikurube https://twitter.com/dmikurube/status/1636290412263665664] What I fundamentally don't understand about the ChatGPT relationship is whether it is actually essential that the query be in natural language. I think that if you are going to use it as a component of something, you might want to build a query that is a bit more mechanical.
>If this is the essence of querying in natural language, then I wonder if prompt engineering can be a pretty serious engineering (and I think it is possible).
>I heard a few years ago that in the machine learning area, for example, in the case of speech processing, it is more accurate to do the whole process at once in an end-to-end manner instead of breaking down the problem into "recognize speech, reduce to language, interpret language, generate response, convert to speech," etc. I was wondering if natural language models and natural language queries I wonder if natural language models and natural language queries fit together naturally or not.

[nishio https://twitter.com/nishio/status/1636355870060847104] The fact that the query is in natural language is not technically essential at all, since it is merely "the current LLM is best at it because it has a lot of training data". I don't think it is technically essential at all. However, if we include the economy, "the majority of homo sapiens would rather query in their native language than learn a programming language," which is the essential problem.
	The fact that most people do not see the problem of using natural language with ambiguous interpretations and do not try to improve it means that most people do not recognize the problem in the first place, and therefore do not understand the value of an artificial language that solves it, and this reduces the incentive to invest in it. to invest in it will decrease.
 >d: I think that's a possibility, of course, but I don't know if it's a known (solved) problem that we can say "it's just a problem," and I don't think it's that obvious.
 I say "only" as an economic, not a technological, matter. It is not determined by technology, but by economics. So we will know when the cost becomes several orders of magnitude lower and we can learn an artificial language for academic interest, irrespective of economic rationality and so on. At present, it is an open question.
 >d: You are probably right in terms of "why the current specific implementation of ChatGPT uses natural language as a query". I wasn't really interested in my own interest there.
I don't think it's getting across very well, but whatever.

>[QuickToshi https://twitter.com/QuickToshi/status/1636557794047578112] If the problem is of interest to humans, I think there is a good chance that natural language, optimized by a long history, is better suited to express it!
　I don't know about this one, I think it's False.
>[_Babbit2 https://twitter.com/_Babbit2/status/1636690556444344321?s=20] In my amateur opinion, if someone is doing research on automatic composition from a large amount of music data......................... I think that someone who is doing research on automatic composition from a large amount of music data would be able to answer this question with a real sense of reality. Even if the music itself has a rich space, I don't think there is a rich mapping between the music and natural language.
　This seems like a good supporting line to point out.
　There is not always a rich mapping between the problem space of human interest and current natural language.

Is the current natural language optimized?
　They are optimized, but I think they are stuck on local minima.
　Limitations in human cognitive abilities prevent most people from being able to use their national languages at a native level.
　　Use of only a few specific languages due to the geographically biased information they have been exposed to since birth
　LLM can be close to a global minimum

[a shift from the era of humans telling machines what to do to the era of machines solving human problems].