Shift from the era of humans ordering machines to the era of machines solving human problems
from [Is it essential that the query be in natural language?]
[* It is only a local optimum for a human to use his/her head to do prompt engineering or other instructions divided into subproblems].
	The phase transition caused by LLM means that computers can now solve human problems e2e.ã€€#end-to-end
		Previously, a human had to split the problem to fit the computer, process the statistics, and model it, but DNN has enabled e2e modeling.
		A properly designed LLM can feed all the problems and their solutions that humans want to solve in e2e.
		GPT4 shows the potential to address multimodal issues.
	[* A shift from the era of humans ordering machines to the era of machines solving human problems e2e] is underway.
		There are many issues to be addressed, such as how to make machines recognize human problems, how to efficiently train such large-scale models, and the data required.
		Prompt Engineering is nothing more than a kind of fine tuning or f ew shot learning, and requires investment from a mid- to long-term perspective.
	If machines can model the wisdom of the world, the benefits are immeasurable.
		Computers can work 24/365, so we need to have a concrete picture of the threats they pose.
>[hrjn https://twitter.com/hrjn/status/1636418867089272832] I'm being half delusional/exaggerating here, but the phase transition that LLM has caused is that computers are now able to solve human problems "reasonably" usefully in e2e. That means that computers can now solve human problems "reasonably well" in e2e. Until now, humans have only had to adapt to computers.
> The reason why there is so much training data is because that is the problem humans want to solve in e2e.
>before the DNN world, the problem was divided into sub-problems so that humans could understand the machine, and humans solved the problem by trial and error, sharing, statistical processing, and modeling. DNN has made e2e modeling possible. ... View more
> In a crude way, a properly designed LLM can feed all the problems and their solutions that can be expressed in human language. All the human wisdom that's been digitized since the beginning of time, all the human wisdom that's been digitized since the beginning of time.
> That is exactly what is happening right now.
> The possibilities presented by GPT4 are pushing it even further multimodally. From text to image. Of course, I thought it could be done because of Stable Diffusion and other text 2 image methods.
> We can already do images and text. Inevitably, video will be covered too, right?
> The world beyond this is the gateway to the all-powerful secretary who "does the rest when you ask her to do it," as the human race used to write about in novels.
> Of course, it will take some time yet, but we are about to shift from the era of humans giving orders to machines.
> The question is how to make machines recognize human problems, what the model for recognition should be, what is the mathematical/informatics basis for efficiently learning such a large scale model, what data to feed the machine, and so on...we are in such a world.
> It is only a local optimum for humans to use their brains to do prompt engineering or other instructions divided into partial problems.
> Essentially, it's about how to efficiently feed the wisdom of humanity to machines. In front of that scale, it doesn't matter how many fucking detailed individual instructions you give.
> The big picture is that the LLM is a fine tuning technique, but the focus is still on fine tuning the LLM.
> I think Prompt Engineering is still more of a task than an artificial language, since it is still just fine tuning and few shot learning.
> But if it is optimized for some weird local-optimal prompt engineering here, I think it will definitely fall behind.
> As a mid- to long-term investment, I believe that unless investments are made in a world where machines can solve human problems e2e, we will lose out before the quantity of data.
> There is no way that a single engineer can beat the wisdom of mankind. I don't know if you are serious or not, but when you say "the code written by GPT is too beautiful", you should quickly realize that there is no way for a human being to win over the quantity of knowledge.
> Software is eating the world, but now computers are starting to eat the world.
> Computers can keep eating 24/365. We should imagine this threat more concretely.
> What if the wisdom of the world were modeled at the Google scale? What for that matter?

[nishio https://twitter.com/nishio/status/1637022954893770754?s=20] Regarding the "shift from the era of humans ordering machines to the era of machines solving human problems e2e", it seems that humans will not be able to verbalize problems to machines. It's only a transitional period, and most humans don't have the ability to properly verbalize the problem, so it's going to be "pour the same data into a machine that a human observes, and the machine will find the problem".
	I'm sure many people associate "pouring the same data into a machine as a human observer" with video and audio, but for organizations where groupware is widespread enough that the majority of business communication is digital text, this could be a bonus opportunity to connect with LLM early.

