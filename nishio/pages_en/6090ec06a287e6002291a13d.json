Hatena2011-02-03
code:hatena
 <body>
 *1296690908*RT: 140 characters to tell people who are trying to find people to RT | day by day I'm a drunk
 140 characters to tell people who are trying to find people and do RT | Sunday I'm a drunk
 http://suikyoh.net/entry-1481.html
 
 >>
 It is dangerous to search for people by spreading RT because "it is impossible to know who the sender is," "it is impossible to correct information," and "the first sentence will continue to spread even if it is corrected or resolved. It is more efficient to prepare a blog or wiki where information can be aggregated, and only use the URL to spread RT.
 <<
 
 Everyone should get into the habit of thinking, when they see or hear something, "Where is the primary source?" When we see or hear something, we should get into the habit of thinking, "Where is the primary source?
 
 *1296691104*Rediscover the Monte Carlo
 I personally am interested in creating game thought routines, etc., so I thought everyone knew about it, but surprisingly, it seems that people don't know that "the current world's strongest Go thought routine is Monte Carlo". Inadvertently, people say things like, "Of course not! I wonder if there is a past memory that "Monte Carlo is so slow in convergence that it is useless" at the root of it. Just as JavaScript was considered an unusable toy language.
 
 The difference between the new Monte Carlo, which is a significant evolution of the Go thinking routine, and the old simple Monte Carlo is that the new Monte Carlo uses the UCB1 evaluation function to determine "good games to search more" and searches preferentially from good games, but that kind of qualitative talk is not very clear. I guess. I thought it would be interesting to see the speed of convergence quantitatively and clearly if I applied the same idea to a Monte Carlo program for finding pi, so I created a program that divides the space and preferentially searches from the most valuable areas to be investigated.
 
 
 ** Result
 I feared that if I explained the logic and sources first, you might not read to the end, so I started with the results (lol).
 
 While the simple Monte Carlo still only knows pi to 3.14 after 2 million trials, the improved Monte Carlo reaches 3.141 after 300,000 trials, and after 200,000 trials it is 3.141593, which is pretty close to pi. Isn't that overwhelming, my troops?
 
 >||
 simple Monte Carlo
 0: pi = 3.133040
 1: pi = 3.141780
 2: pi = 3.142373
 3: pi = 3.141050
 4: pi = 3.142184
 5: pi = 3.142260
 6: pi = 3.142771
 7: pi = 3.143790
 8: pi = 3.143636
 9: pi = 3.142952
 10: pi = 3.143011
 11: pi = 3.143880
 12: pi = 3.144342
 13: pi = 3.144023
 14: pi = 3.143701
 15: pi = 3.143102
 16: pi = 3.143104
 17: pi = 3.142973
 18: pi = 3.143078
 19: pi = 3.143240
 
 Improved Monte Carlo
 0: pi = 3.142376
 1: pi = 3.142209
 2: pi = 3.141998
 3: pi = 3.141850
 4: pi = 3.141732
 5: pi = 3.141667
 6: pi = 3.141708
 7: pi = 3.141727
 8: pi = 3.141715
 9: pi = 3.141703
 10: pi = 3.141722
 11: pi = 3.141702
 12: pi = 3.141652
 13: pi = 3.141622
 14: pi = 3.141634
 15: pi = 3.141627
 16: pi = 3.141620
 17: pi = 3.141604
 18: pi = 3.141598
 19: pi = 3.141593
 ||<
 
 The execution time is indeed about four times slower. However, even if the number of trials is reduced by a factor of four, the improved Monte Carlo still converges faster.
 >||
 simple Monte Carlo
 real	0m0.106s
 user	0m0.038s
 sys	0m0.003s
 
 Improved Monte Carlo
 real	0m0.422s
 user	0m0.406s
 sys	0m0.005s
 ||<
 
 ** Rationale
 Explanation of the theory. In short, the space to be searched in Monte Carlo is divided into a mesh of WIDTH * WIDTH, and each square is tried in order of increasing score. score is the "average value of how much the result varies when one trial is made in that square. The problem is how to calculate the score...
 
 First, each trial returns a 0/1 value for "in/out of the circle," so it can be considered a Bernoulli process. a + b trials yielded 1 a times and 0 b times, what is the probability of getting 1 on the next trial? It is obvious that it is not a / (a + b). This would lead to the erroneous conclusion that if 1 is obtained in one trial, "1 is sure to be obtained in the next one".
 
 We are talking about the probability of 1, i.e., what is the mean value of μ, the mean value of the original Bernoulli distribution. The conjugate prior distribution of μ is Beta distribution, and since the textbook says that the posterior distribution after a + b trials where 1 is obtained a + b times and 0 is obtained b times is Beta(a + 1, b + 1) (yeah), we can conclude that the probability p of obtaining 1 is (a + 1) / (a + b + 2).
 
 The "percentage of circles in this square" = "the maximum likelihood estimate of the probability of 1 in this square" = "a / (a + b)" will change to (a + 1) / (a + b + 1) with a probability of p and to a / (a + b + 1) with a probability of (1 - p), so the average amount of update in these two ways is normally obtained. The average amount of updates can be obtained by multiplying the amount of updates in the two ways by the probability and adding them together. This is the score function in the code below.
 
 (As I write this, I'm calculating the change in a / (a + b), but maybe (a + 1) / (a + b + 2) would be more appropriate? I had a feeling that this was the case. (I think the maximum likelihood estimator of the percentage of circles in a square is a / (a + b), so I think the current policy is correct, but I was worried for a moment, so I wrote it down.)
 
 (I should add, so that there is no misunderstanding, that this evaluation function is not UCB1. In Go, we look for "moves that are likely to win," whereas in this pi estimation, we look for "black-and-white split areas," so UCB1 could not be used.)
 
 ** Code
 If there is something wrong, please do not be afraid to poke at it. In the main, we are just doing "divide the search space into WIDTH * WIDTH and search from the point with the highest SCORE" as described above.
 
 >|cpp|
 #include <stdio.h>
 #include <stdint.h>
 #include <vector>
 #include <queue>
 using namespace std;
 
 // http://www.jstatsoft.org/v08/i14/xorshift.pdf
 uint32_t xor128() { // period is 2^128-1
     static uint32_t x=123456789,y=362436069,z=521288629,w=88675123;
     uint32_t t;
     t=(x^(x<<11));x=y;y=z;z=w; return( w=(w^(w>>19))^(t^(t>>8)) );
 }
 
 const size_t ITER_PER_PRINT = 100000;
 const size_t NUM_ITER = 20;
 
 int monte(){
   size_t count = 0;
   for(size_t iter = 0; iter < NUM_ITER; iter++){
     for(size_t i = 0; i < ITER_PER_PRINT; i++){
       uint32_t v = xor128();
       uint32_t u = xor128();
       double x = v / 4294967295.0;
       double y = u / 4294967295.0;
       if(x * x + y * y < 1){
 	count++;
       }
     }
     printf("%d: pi = %f\n", iter, double(count) / ITER_PER_PRINT / (iter + 1) * 4);
   }
 }
 
 
 inline double score(size_t a_, size_t b_){
   double a = a_ + 1, b = b_ + 1;
   double n = a + b + 2;
   return double(2 * a * b + n) / n / (n + 1) / (n + 2);
 }
 
 int monte2(){
   size_t WIDTH = 100;
   size_t N = WIDTH * WIDTH;
   vector<size_t> denom(N);
   vector<size_t> count(N);
   priority_queue<pair<double, size_t> > queue;
   for(size_t i = 0; i < N; i++){
     queue.push(make_pair(score(0, 0), i));
   }
   for(size_t iter = 0; iter < NUM_ITER; iter++){
     for(size_t i = 0; i < ITER_PER_PRINT; i++){
       uint32_t v = xor128();
       uint32_t u = xor128();
       size_t index = queue.top().second;
       queue.pop();
       double x = v / 4294967295.0 / WIDTH + 1.0 / WIDTH * (index % WIDTH);
       double y = u / 4294967295.0 / WIDTH + 1.0 / WIDTH * (index / WIDTH);
       denom[index]++;
       if(x * x + y * y < 1){
 	count[index]++;
       }
       queue.push(make_pair(score(count[index], denom[index] - count[index]), index));
     }
     double area = 0.0;
     for(size_t i = 0; i < N; i++){
       area += 1.0 / N * count[i] / denom[i];
     }
     printf("%d: pi = %f\n", iter, area * 4);
   }
 }
 
 int main(){
   monte();
   monte2();
 }
 ||<
 </body>
 <comments>
 <comment>
 <username>showyou</username>
 <body>I didn't read it carefully, but why don't you use MCMC? And </body>.
 <timestamp>1296750855</timestamp>
 </comment>
 </comments>

[Hatena Diary 2011-02-03 https://nishiohirokazu.hatenadiary.org/archive/2011/02/03]