Test it now that it has been integrated with the traditional question generation algorithm.

[*** summarized by AI, modified by Human].
 LangChain has a Max marginal relevance mouth
 	but the one that inherits the abstract class is not implemented.
 LlamaIndex can map an embedding vector to it by passing a list of texts.
 	When a query is issued, relevant documents are picked up based on a vector.
  The vectorization for LlamaIndex text is stored in local JSON.
 LlamaIndex uses OpenAI's embedded API.
  I don't know how the embedding API is implemented or if it is extracted from some layer.
 Use LlamaIndex because LangChain has trouble working.
 	Due to mysterious problems with FAISS, LlamaIndex is currently used.
 We have not yet confirmed the implementation of LlamaIndex.
 The next step is to review the LlamaIndex implementation and read and understand the code.

[*** summary by AI].
 LangChain has a Max marginal relevance mouth, but the one that inherits the abstract class is not implemented.
 LlamaIndex can map an embedding vector to it by passing a list of texts.
 When a query is issued, relevant documents are picked up based on a vector.
 LlamaIndex uses OpenAI's embedded API.
 Use LlamaIndex because LangChain has trouble working.
 We have not yet confirmed the implementation of LlamaIndex.
 Due to mysterious problems with FAISS, LlamaIndex is currently used.
 When LangChain is trained, we do not know if it will be extracted from some layer.
 The vectorization for LlamaIndex text is stored in local JSON.
 The next step is to review the LlamaIndex implementation and read and understand the code.


[/nishio/kei.icon]What would you like to see happen in this conversation? (GPT)
[/nishio/human.icon]Test it now that it has been integrated with the conventional question generation algorithm.
[/nishio/kei.icon]Thank you. I wish you success in testing the new algorithm.
[/nishio/human.icon]We'll talk a lot to decide what to do next.
[/nishio/kei.icon]What exactly would you like to talk about?
I've read [/nishio/human.icon]LlamaIndex and LangChain implementation, but some of my predecessors are in mysterious trouble when using FAISS with LangChain, so I think I'll proceed with the current LlamaIndex implementation for the time being
Please tell us about the implementation of [/nishio/kei.icon]"LlamaIndex". What exactly did you implement?
[/nishio/human.icon]I haven't read much about that implementation yet. It works without any problems, and the vector index is placed in the local JSON, so it would be easy to experiment with features that the library does not provide.
[/nishio/kei.icon] It's an implementation of "LlamaIndex" with a vector index placed on the local JSON.
[/nishio/human.icon]Yes, LangChain has Max marginal relevance, which is promising, but there are a lot of abstract classes that inherit from other classes and don't implement their methods, so I don't know which ones are possible without looking at the specific classes. FAISS could do it.
I am not sure which classes implement Max marginal relevance, since the classes that inherit from the abstract class of [/nishio/kei.icon]"LangChain" do not implement the Max marginal relevance method. But is there a possibility to do it by using FAISS?
[/nishio/human.icon]Yes. But, however, some people are having trouble moving with FAISS, so we're not going to go down the same road.
[/nishio/kei.icon]You mentioned that the Max marginal relevance implementation of "LangChain" could be solved by using FAISS, but what exactly was the problem?
[/nishio/human.icon]I deployed it to Heroku and it stopped working even though the version was supposed to be aligned, and it died due to function argument mismatch, so I'm thinking maybe it's supposed to be aligned but it's not.
[/nishio/kei.icon]What are the current problems with "LangChain"?
[/nishio/human.icon]I'm not talking only about LangChain, but building a program on top of a library that is being updated daily is like walking on an unfrozen lake.
[/nishio/kei.icon]You seem to be finding it difficult to create the program. What do you think is the reason why the work is not progressing well?
[/nishio/human.icon]When the cushion of thick abstraction layers is drawn so that even those who don't have a grounded understanding can easily do something, it's comfortable to sit on, but when you try to walk, you'll stumble. That's fine for those who are content to just type in what the tutorial says and move it around, but not for those who want to move around.
Where is [/nishio/kei.icon]"LangChain" part of the library you use?
[/nishio/human.icon]Putting that aside, ask about LlamaIndex.
[/nishio/kei.icon]You said you were going to ask a question about LlamaIndex, can you explain LlamaIndex in detail?
[/nishio/human.icon]A method to allow ChatGPT to refer to external material by mapping vectors to text fragments, selecting appropriate text for queries, and loading them into prompts to ChatGPT.
[/nishio/kei.icon]How did you learn about "LangChain"?
[/nishio/human.icon]ðŸ‘ŽLangChain
Please tell us more about the functionality of [/nishio/kei.icon]"LlamaIndex".
If you pass a list of [/nishio/human.icon] texts, you can create a VectorStore that maps an embedding vector to it. I think this is just hitting OpenAI's embedding API. When you issue a query, it picks up relevant documents based on the vectors. I believe this is inner product similarity, but I haven't checked.
[/nishio/kei.icon]Please elaborate on the "vector" in "LlamaIndex".
[/nishio/human.icon]There is a technology that maps text to a vector of a little over 1,000 dimensions that reflects its meaning. A vector created by it.
How are [/nishio/kei.icon]"LlamaIndex" embedding vectors created?
Create with [/nishio/human.icon]OpenAI's API
[/nishio/kei.icon]Regarding the embedded vectors created by the "OpenAI" API, how does the API work?
I wonder if [/nishio/human.icon]Transformer is learned and then extracted from some layer? Don't know.
Where are [/nishio/kei.icon]"LlamaIndex" vectors stored?
[/nishio/human.icon] It's stored in local JSON.
What kind of data is stored in the local JSON of [/nishio/kei.icon]"LlamaIndex"?

https://keicho.netlify.app/#talk=TqbPiBoeyzjYM4zuQsu8
#KeichobotLog
