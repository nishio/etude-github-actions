pScrapboxAutoTrans2023-03-25
2023-03-25 [pScrapboxAutoTrans]

Whether to put the translations in this Scrapbox or not.
ã€€I have a whole book's worth of content in English at [Engineer's way of creating knowledge], but almost a year later, I haven't experienced any "connection! I have not experienced any "connection" at all!
ã€€ã€€Sometimes the connection is unexpected, but it's not a happy connection.
ã€€If the translation is immediately added to this Scrapbox as a separate page, there will be two similar pages in a row
ã€€ã€€the other
ã€€Provide both Japanese and English on the page.
ã€€ã€€I think this is better, but not better.
ã€€Fundamentally, the problem is that the page list is not customizable.

[English Language Support].
	>How about setting up a [social trigger] by writing casually in Scrapbox, automatically machine translating it, transcribing it to the English version of the Scrapbox project, and then tweeting it on an English account so that I get notified when there are reactions?
		[" Tweeting with an English account
		No reaction on Twitter.

[Scrapbox Englishization Project]
 >Scrapbox's API seems cumbersome to achieve sequential updates.
 	Yes
 >As a small start, you could first export it in JSON, translate it, and import it.
 >Insert `(auto-translated from [Japanese http://....])' in the first line? and insert `(auto-translated from [Japanese ])' at the beginning of the line?
 	Mechanical text in the first line causes the card display to be [Garbage House].
 	Iconic notation if you want to put it at the beginning

[ScrapboxAutoTrans Development Diary 2021-12-28].
	>In the future, it would be good to use Github Action to spit it out as a static file and host it on Github Pages or something.
		Well, at least I'd better diversify my domains because they might not pay for the maintenance of the nhiro domain after I'm dead and they might notice that I'm dead after I'm gone.

2023-03-26
stay awake during sleep

The problem is complex.
ã€€How to translate documents that are updated daily
ã€€How to show what has been translated
ã€€Where to place the translated
Should [split into simple problems

I'm getting to the point where I can use Github Action to get it.
ã€€Can I keep the translated data too?
ã€€Is there something already in English that doesn't need to be translated?
ã€€ã€€You have manually translated content.

ã€€estimate
	ã€€13,115,848 characters
	from [Engineers' Intellectual Production English Project].
		>I exported the whole thing and estimated that it would cost me 60,000 yen [to translate the whole thing] since it has 24M characters.
	from [cost of machine translation].
		>Â¥2,500 per 1 million characters
	Whether character is a Unicode character or bytes
	27,493,421 for bytes.
	ã€€This one is closer to the last estimate.
ã€€Estimated at less than 70,000 yen
ã€€ã€€Feeling that it is less than 1% of annual income and will pay for itself in one year if productivity improves by 1% in the coming year.
ã€€execution (e.g. program)
ã€€ã€€I ran 300 pages and it was $400.
ã€€Whole execution in progress
ã€€memo
ã€€ã€€I had left it for almost a year thinking about the details, but I decided that "procrastination" was no longer an option, so I decided to do it today, and "done is better than perfect.
ã€€ã€€I don't care about the issue of the link string not being an exact match because I can use a vector search.
ã€€ã€€It's cached line by line.
ã€€ã€€ã€€So if you add one line to a large page, only one line is translated.
ã€€ã€€Maintain indentation and line-by-line translation because of bullet points
ã€€ã€€ã€€I'm separating the indentation from the text before translating.
ã€€ã€€ã€€So different indentation of the same content is a cache hit.
ã€€ã€€Local language judgment is applied and lines that are not Japanese are passed through without translation.
ã€€ã€€ã€€This means that source code, image notation, etc. are no longer eligible for translation.
ã€€ã€€When you find a mistranslation, you can use your hand to correct the cache.
ã€€I have no idea what the view is.
ã€€ã€€You're not even thinking about it?
ã€€ã€€They're on Github in text format.

2023-03-30
	It was rather rubbish with errors and I didn't put a retry on, so I haven't finished it yet.
		I kept retrying with weird queries and risked wasting money, so until I knew it was okay, I'd just eyeball the error and retry manually.
	https://github.com/meganii/sandbox-github-actions-scheduler
	ã€€I'm referring to the
	https://github.com/nishio/etude-github-actions
ã€€ã€€It smells like...
ã€€ã€€We haven't run it through Github Action yet.
ã€€>[https://twitter.com/TwitterDev/status/1641222782594990080 @TwitterDev]: Today we are launching our new Twitter API access tiers! Weâ€™re excited to share more details about our self-serve access. ðŸ§µ
 	Good timing! I want to "translate my Scrapbox into English once a day and then have GPT tweet a summary in English.

ã€€langdetect seems like a good idea to stop.
ã€€ã€€There are many misjudgments for short sentences, and because of probabilistic behavior, there are cases where "once we judged it to be English, but this time we judged it to be Japanese, so we translated it".
ã€€ã€€	https://github.com/nishio/etude-github-actions/commit/e86ca8e8119c492c72c4c1e58982b7830924c85b#diff-7bd0b7387ba890dfb8a3302f1795f74db56eba845bdd467f9c47f04717bab873
ã€€ã€€Like this, I'd say, "I think `#Amanojaku #Devil's Advocate` is English," and then leak a one-line translation.
ã€€ã€€Q: If I put in the full text, won't it be judged correctly? A: Yes, and it will also translate all the source code without Japanese that is placed on the page with the Japanese explanation.
ã€€ã€€If it contains even one character in the Japanese domain, it should be judged as Japanese.


https://www.deepl.com/account/usage
	[https://gyazo.com/a40aa315dd34aa7c9ada756b0bfb545a]
ã€€Now this should be about half way there in terms of page count, so it's surprisingly inexpensive, right? I guess.

2023/4/1
ã€€Successfully completed.
ã€€[https://gyazo.com/796feeeb47fc4b9e3ddcbe3627ec60b0]
ã€€23,000 yen. Quite a bit cheaper than expected.
ã€€ã€€I was going to estimate it at $70,000 in bytes, but apparently it's a Unicode character.
	ã€€13,115,848 characters / 27,493,421bytes
		The number of characters was reduced from 13M to 9.3M due to the removal of indentation and line breaks and the removal of duplicate strings in the cache.

First, we turn zeros into ones, then we improve them.
ã€€Where to place the translated
ã€€â†’ For now, it's on Github.
ã€€ã€€ã€€â†’How to show what has been translated
ã€€ã€€ã€€ã€€https://github.com/nishio/etude-github-actions/blob/main/nishio/pages_en/59280ec2ba093700118f9bc5.json
ã€€ã€€ã€€ã€€I wondered why it was red, but it's a scrapbox with a json extension.
ã€€ã€€ã€€ã€€Can be read on Github if it can be converted to Markdown
ã€€ã€€ã€€ã€€But I think it's a bone of contention to make the link connect in a Scrapbox-like way.
ã€€ã€€ã€€ã€€Can [mem.nhiro.org] be loaded from Github?
ã€€How to translate documents that are updated daily
ã€€ Let's try to update it with Github Actions.
ã€€ã€€Time measurement at hand
ã€€ã€€ã€€`python main.py  2578.84s user 270.36s system 98% cpu 48:27.16 total`
ã€€ã€€ã€€What's taking so long?
ã€€ã€€ã€€Ah, updating the cache.
ã€€ã€€ã€€Fixed [Github https://github.com/nishio/etude-github-actions/commit/98ac9d7e2267f3bc7faf2c02720c7d00bb7638b2]
	ã€€ã€€	`python main.py  3.73s user 2.56s system 68% cpu 9.118 total`

Re-crawl for updates during the past week
	`python main.py  39.36s user 14.77s system 10% cpu 8:49.13 total`
retranslation
	`total 28492485 no_cache 156769 ratio 0.005502117488172758`
	`python main.py  48.04s user 7.02s system 3% cpu 24:02.17 total`
	ã€€Most of the time waiting for translation APIs

Execute with Github Actions
ã€€It's been an hour and it's not over.
ã€€I'd love to find out in more detail where it's slow.
ã€€I've got the page fetch and translation in one script, so I don't know which is the problem or what.
ã€€ã€€If acquisition is slow
ã€€ã€€ã€€I'm taking all of them. That's right.
ã€€ã€€ã€€ã€€The update date and time are known at the initial candidate stage, so you only need to take the updated ones.
ã€€ã€€ã€€ã€€For those for which you have administrative privileges, you can use the export API.
ã€€ã€€If translation is slow
ã€€ã€€ã€€Because you're waiting for the API response in series.

Took six hours and it's been cancelled.
	[https://gyazo.com/7da36b796fac0b2cdaba26c2e1fe6ff1]
	Logged.
ã€€Crawl's done, and it's stopped in the process of translating.
	`  9%|â–‰         | 1368/14461 [00:00<00:07, 1831.53it/s]`
	ã€€I would think it would be slower if the cache wasn't working...
	`Error: The operation was canceled.`

2023/4/5
 I suspected the cache might not be working, but it wasn't.
 I changed various debug outputs to check the situation, but for some reason it completed easily. Huh?
 ã€€I realized after a night's sleep that maybe the progress display was incompatible with the irregular terminal operations and the Github Actions mechanism for capturing logs and showing them in real time on the web?

2023/4/6
ã€€First, import automatically into Scrapbox.
ã€€ã€€Ideally, you should connect to [mem.nhiro.org], but you can start with an easy step
ã€€I want to auto Tweet the activity digest.
ã€€ã€€First of all, "Output Tweet contents to a file" and "Tweet by a human being".

[experiment 2023-04-06].
