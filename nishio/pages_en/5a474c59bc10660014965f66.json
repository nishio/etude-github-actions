No numerical criteria should be used to evaluate researchers.
I think it's a bad idea to evaluate researchers by the number of papers or patents they have."
The source is said to be [Hiroshi Maruyama], former director of [IBM Research Laboratory].
[To all aspiring corporate researchers] for more information.


#評価 #数値基準 #定量的KPI

[tokoroten https://twitter.com/tokoroten/status/946988934646530048]
 >I'm looking for a source for a story about the director of an IBM or some other research institute who said, "If you make the performance evaluation criteria of researchers public, they will act accordingly and fall into [local optimum]. I'm trying to find a source for this story, but I can't find it. Hmmm, I wonder who said that.
		[ceekz https://twitter.com/ceekz/status/946989579952726016]
   >[https://www.amazon.co.jp/exec/obidos/ASIN/4764903822/ceek-22/ref=nosim 企業の研究者をめざす皆さんへ―Research That Matters 単行本 – 2009/11/4 丸山 宏]
   >I think it was this book
  Hiroshi Maruyama was the Director of IBM Tokyo Research Laboratory from 2006 to 2009, and has been the Chief Strategy Officer of Preferred Networks, Inc. since April 2016.
  [https://twitter.com/ReiOdaira/status/946993309150531585 ReiOdaira]
   >I have heard that story from Mr. Maruyama himself, but to be precise, he said that "if we set a strict numerical standard for evaluation, all researchers are so smart that they will take actions optimized to it" rather than making the evaluation criteria public.
   >At the Institute's general meeting, you said, "So we don't establish numerical criteria for evaluation. I don't know if they really didn't establish them or just didn't disclose them.
		dmikurube
  	>I was also a student, and I heard this at the all hands meeting at the institute, but it was something like, "If you can really create appropriate standards, you may be able to create them, but it is practically impossible, and the world and the environment change so quickly that it is impossible to keep up with them and change them every time. So, everyone should think about what they need to do to make a real [impact] on the world, and then do their own work or create their own work.

	I received a copy of "[To all aspiring corporate researchers]," so I'll summarize it lightly.
 	Not only companies, but especially corporate researchers should [have an impact on the world].
  We call [impactful research] [Research That Matters].
  p.3
  	[https://gyazo.com/fa4834f64e4cea6e17b00f1665e3a901]
   	[Pasteur Quadrant]
    [Bohr], [Edison], [Pasteur].
		The letter "About Evaluation" is introduced on p. 141
  	Indicators based on the number of papers or citations do not apply well to corporate research institutions
   Because the value of our research results is first and foremost expressed in our advanced products and services
   Evaluation should be [additive method
   	Otherwise, goals are set low at the beginning of the year and motivation to work outside of those goals is lowered.
   	[Evaluating by the percentage of goals met leads to ignoring opportunities].
     If an opportunity comes along that you didn't expect when you set your goal, you should seize it.
     But if you devote time and resources to things that are not planned, the probability of accomplishing what you planned to do goes down.
   [Transparency of Evaluation
   	Transparency means making clear the reasons for the evaluation.
    It's not about creating a standard in advance that says, "If you get this far, you'll get an A."
    	This criterion is a [subtractive point method] that says, "If you don't get that far, you don't get an A."
    Measuring by the number of patents and papers is not appropriate because there is a huge gap in the quality of individual patents and papers.
    If you say, "I have made an impact on the world and I want to be recognized for it," you should speak up and claim it.
    	Responsibility to [appeal] # Appeal Responsibility
    

今後の議論
	From the evaluator's point of view, "Then how should I evaluate?"
  Challenges not only for researchers, but for all types of work where results cannot be quantitatively measured.
  The type of work whose results cannot be measured quantitatively = Drucker's [knowledge worker] concept.
	From the perspective of the person being evaluated.
  When there is no numerical standard for evaluation, what can we claim as an achievement?"
  	→ Claims to have "made an impact on the world
  What to do when numerical criteria for evaluation are established?"
  	There are organizations and people who work there where numerical standards have already been introduced.
  	Even if it seems foolish to set a numerical standard, it is within the freedom of individual organizations
   On the other hand, the extent to which workers in the organization are free to devote any amount of effort to improving their evaluation of the organization based on strange criteria is a matter of freedom on the part of the workers
   → Just ignore the evaluation criteria and act accordingly.
