People who assume that correct knowledge is given by authority.
>[knshtyk https://twitter.com/knshtyk/status/1637302053914673152] As was the case during the period when everyone was instantly exposed to image generation AI, there are always people who are spreading their own rules of Prompting (or Prompt Engneering) methods and notations (less effective and more esoteric than regular input) for text AI. I wonder if it's just a typical windfall surrounding generative AI, though there are always people trying to promote Prompting (or Prompt Engneering) methods and notations (less effective and more esoteric than regular input).
> I think it is a useful trial to find a way to communicate with LLMs, but there are many people who are trying to use it for their own positioning by flaunting their "strange and esoteric" and "great job" aspects, and overall, it adds groundless noise and hides the really useful information. I would like to give them a break.

[nishio https://twitter.com/nishio/status/1637339135152390144] I think this is a phenomenon that generates a feedback loop between "people who assume that correct knowledge is given by an authority" and "people who try to be an authority by giving something that looks like knowledge [confidently] even if it is not correct" when something new appears and there is no [textbook] that is an [authority] yet. and "people who try to become an authority by giving something that looks like knowledge [with confidence], even if it is not correct", which I think is a phenomenon that generates a feedback loop.
	People who assume that correct knowledge is given by authority" are eager to have someone give them knowledge, and they don't think to "verify for themselves whether the knowledge they are given is correct or not," so supply and demand are matched.

-----
and I wrote to Scrapbox and this was suggested.
[Two kinds of spirituality]

It is one-sided to think of a cult as "created by a guru" and can be viewed as a phenomenon where a system is formed by a combination of guru and followers, and when that system has the ability to increase followers, it "gradually grows larger and larger." Putting meaningless and complex prompts into AI is [ cargo cult] rituals as well.

> Feynman pointed out that the followers of the cargo cult outwardly correctly build airports, headsets, and bamboo "antennas," but the planes never come. Feynman argued that scientists also often fall into that folly, but only imitate the form of such science...something not worthy of respect or support.
https://ja.wikipedia.org/wiki/カーゴ%E3%83%BBカルト


-----
https://twitter.com/okapies/status/1637643975648772096
Similarly, I think it will be a few more years before there are a large number of people who say "ChatGPT is right because ChatGPT said so".

https://twitter.com/nishio/status/1637654028430741505
There are still tons of people who say, "It's right because it was written in the textbooks.
The LLM-generated description is placed on Wikibooks, "This is different from the textbook!" and the result is that the textbook content is converted into a format that can be learned by LLMs, and the next LLM will say exactly what the textbook says. This will happen in a few years in areas that already have textbooks and are mainly written in text.

[Seeing is believing.]
