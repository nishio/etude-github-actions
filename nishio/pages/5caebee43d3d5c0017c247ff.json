{
  "id": "5caebee43d3d5c0017c247ff",
  "title": "Playing Atari with Deep Reinforcement Learning",
  "created": 1554956007,
  "updated": 1554958151,
  "lines": [
    {
      "id": "5caebee43d3d5c0017c247ff",
      "text": "Playing Atari with Deep Reinforcement Learning",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956007,
      "updated": 1554956026
    },
    {
      "id": "5caebef3aff09e0000315fe6",
      "text": "2013年の論文で、コンピュータにATARIのゲームをさせるもの。ゲームごとにアルゴリズムを調整したりせず単一の方法でチャレンジして3つのゲームで人間のエキスパートを超えた。",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956020,
      "updated": 1554958151
    },
    {
      "id": "5caebee6aff09e0000315fe4",
      "text": "https://arxiv.org/abs/1312.5602",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956007,
      "updated": 1554956007
    },
    {
      "id": "5caebee6aff09e0000315fe5",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956007,
      "updated": 1554956007
    },
    {
      "id": "5caebf01aff09e0000315fe7",
      "text": "[Paper Digest]してみた",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956033,
      "updated": 1554956046
    },
    {
      "id": "5caebf0daff09e0000315fe9",
      "text": "What this paper is about",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956046,
      "updated": 1554956061
    },
    {
      "id": "5caebf1caff09e0000315fea",
      "text": "\tIntroduction and Objective",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956064
    },
    {
      "id": "5caebf1caff09e0000315feb",
      "text": "\t\tThis paper demonstrates that a convolutional neural network can overcome these challenges to learn successful control policies from raw video data in complex RL environments.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956066
    },
    {
      "id": "5caebf1caff09e0000315fec",
      "text": "\t\tTo alleviate the problems of correlated data and non-stationary distributions, we use ar X iv :1 31 2. 56 02 v1 [ cs.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956068
    },
    {
      "id": "5caebf1caff09e0000315fed",
      "text": "\t\tOur goal is to create a single neural network agent that is able to successfully learn to play as many of the games as possible.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956070
    },
    {
      "id": "5caebf1caff09e0000315fee",
      "text": "\t\tRecent advances in deep learning have made it possible to extract high-level features from raw sensory data, leading to breakthroughs in computer vision and speech recognition.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956072
    },
    {
      "id": "5caebf1caff09e0000315fef",
      "text": "\t\tFurthermore, in RL the data distribution changes as the algorithm learns new behaviours, which can be problematic for deep learning methods that assume a fixed underlying distribution.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956074
    },
    {
      "id": "5caebf1caff09e0000315ff0",
      "text": "\tWhat you can learn",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956077
    },
    {
      "id": "5caebf1caff09e0000315ff1",
      "text": "\t\tResults",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956078
    },
    {
      "id": "5caebf1caff09e0000315ff2",
      "text": "  Discussion and Conclusions",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956082
    },
    {
      "id": "5caebf1caff09e0000315ff3",
      "text": "\t  This paper introduced a new deep learning model for reinforcement learning, and demonstrated its ability to master difficult control policies for Atari 2600 computer games, using only raw pixels as input.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956084
    },
    {
      "id": "5caebf1caff09e0000315ff4",
      "text": " \t We also presented a variant of online Q-learning that combines stochastic minibatch updates with experience replay memory to ease the training of deep networks for RL.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956086
    },
    {
      "id": "5caebf1caff09e0000315ff5",
      "text": "  \tOur approach gave state-of-the-art results in six of the seven games it was tested on, with no adjustment of the architecture or hyperparameters.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1554956061,
      "updated": 1554956087
    }
  ]
}