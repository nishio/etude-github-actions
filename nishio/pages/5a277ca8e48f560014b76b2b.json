{
  "id": "5a277ca8e48f560014b76b2b",
  "title": "モデルの評価をモデルの選択に使う",
  "created": 1512537260,
  "updated": 1512538799,
  "lines": [
    {
      "id": "5a277ca8e48f560014b76b2b",
      "text": "モデルの評価をモデルの選択に使う",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537260,
      "updated": 1512537270
    },
    {
      "id": "5a277cb6aff09e000073490c",
      "text": "思考の整理のためのページ",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537270,
      "updated": 1512537438
    },
    {
      "id": "5a277d21aff09e000073490f",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537377,
      "updated": 1512537377
    },
    {
      "id": "5a277cbaaff09e000073490e",
      "text": "機械学習でモデルを学習した後、何らかの方法で「モデルの評価」を行って「モデルの良さ」(例えば精度など)の値を得ることが広く行われている。さらにその得られた値が良いモデルを選ぶという「モデルの選択」もよく行われている。",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537275,
      "updated": 1512537374
    },
    {
      "id": "5a277d22aff09e0000734910",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537378,
      "updated": 1512537378
    },
    {
      "id": "5a277cbaaff09e000073490d",
      "text": "これに対する批判「モデルの評価結果を最大化するモデル選択は、評価に使ったデータへの過学習を起こす」",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537275,
      "updated": 1512537423
    },
    {
      "id": "5a277d5aaff09e0000734912",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537434,
      "updated": 1512537434
    },
    {
      "id": "5a277d28aff09e0000734911",
      "text": "モデル評価の方法(割合は一例)",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537384,
      "updated": 1512537482
    },
    {
      "id": "5a277d82aff09e0000734914",
      "text": "\tA: データの2割を取り分け、残り8割で学習したモデルの性能を、2割のデータで評価する(ホールドアウト法)",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537475,
      "updated": 1512537525
    },
    {
      "id": "5a277d99aff09e0000734916",
      "text": " B: データを2割づつの5つに分割する(D1, D2, D3, D4, D5)。 D1+D2+D3+D4で学習したモデルをD5で評価し、D2+D3+D4+D5で学習したモデルをD1で評価し、と5回の評価を行い結果を平均する(クロスバリデーション法)",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537498,
      "updated": 1512537598
    },
    {
      "id": "5a277d99aff09e0000734918",
      "text": " C: データを6割、2割、2割に分割する(D1, D2, D3)。D1で学習したモデルをD2で評価する。その後D1+D2で学習したモデルをD3で評価する。",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537498,
      "updated": 1512537712
    },
    {
      "id": "5a277f49aff09e0000734930",
      "text": "  一般的には「パラメータを変えてD1を学習しD2で評価すること」を繰り返してR2が最大となるパラメータを求めた上で、そのパラメータをD1+D2で学習したものをD3で評価する",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537929,
      "updated": 1512538004
    },
    {
      "id": "5a278195aff09e0000734937",
      "text": "   D2で評価した結果(R2)とD3で評価した結果(R3)の使い分けが良くわからない",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538517,
      "updated": 1512538518
    },
    {
      "id": "5a277fa4aff09e0000734931",
      "text": "    R2を元にモデル選択をするんだったら、R3の値は何に使うのか？眺めて満足するだけ？",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538021,
      "updated": 1512538521
    },
    {
      "id": "5a277fb9aff09e0000734932",
      "text": "   R3の値を見て「思ったより低いぞ」と言って別の試行をやるのなら、これはモデル選択の一環であって、R2とR3を分けたことにあまり意味がないのではないか。",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538041,
      "updated": 1512538339
    },
    {
      "id": "5a278028aff09e0000734933",
      "text": "   R3の値をモデル選択に使わないなら「試行錯誤に使うデータD2と最終評価専用のデータD3に分けました」という主張は筋が通る。でも実際はモデル選択に使うことが多いのでは？",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538152,
      "updated": 1512538387
    },
    {
      "id": "5a277f06aff09e000073492f",
      "text": "   例えば「D1+D3で学習してD2で評価し、D1+D2で学習してD3で評価し、平均を取る」という形なら「5foldのクロスバリデーションがしたかったんだけど計算コストが高いから2回だけやった」という形で納得できる",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537863,
      "updated": 1512538360
    },
    {
      "id": "5a278128aff09e0000734934",
      "text": "   R3がR2に比べてどの程度悪かったらダメだと考えるのかが明瞭ではない。「D1+D2で学習してD3で評価する」という実験は何を目的として行うもので、どういう状態を成功と定義するのかが曖昧。実験前にそれを決める必要があるのでは？",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538409,
      "updated": 1512538494
    },
    {
      "id": "5a277e7caff09e0000734927",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537724,
      "updated": 1512537724
    },
    {
      "id": "5a277e7caff09e0000734928",
      "text": "モデルの選択",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537724,
      "updated": 1512537728
    },
    {
      "id": "5a277e80aff09e0000734929",
      "text": "\tSVMがいいかな、LRがいいかな、という選択",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537728,
      "updated": 1512537740
    },
    {
      "id": "5a277e8caff09e000073492a",
      "text": " SVMのパラメータをいくらにしようか、という選択",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537740,
      "updated": 1512537752
    },
    {
      "id": "5a277e97aff09e000073492b",
      "text": " NN系において何epochで止めるか(学習epoch数というパラメータをいくらにするか)の選択(early stopping)",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537752,
      "updated": 1512537824
    },
    {
      "id": "5a2781f1aff09e000073493a",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538610,
      "updated": 1512538611
    },
    {
      "id": "5a277ef4aff09e000073492d",
      "text": " early stoppingでは普通A(ホールドアウト)が使われている",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512537844,
      "updated": 1512538629
    },
    {
      "id": "5a2781b9aff09e0000734938",
      "text": " 計算コストが安いならB(クロスバリデーション)をすればよい",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538553,
      "updated": 1512538637
    },
    {
      "id": "5a27821baff09e000073493b",
      "text": " Cは例えば、Bをすることが計算量的に困難なシチュエーションで、でもAを行った場合に「それはパラメータサーチの段階で検証データにoverfitしているのではないか」とつっこまれることが予想される場合に、「取り分けておいたデータで検証してこの精度が出たのだからパラメータサーチの影響ではない」と反論する時には有用そう。",
      "userId": "582e63d27c56960011aff09e",
      "created": 1512538651,
      "updated": 1512538797
    }
  ]
}