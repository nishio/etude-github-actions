{
  "id": "6322ae16886c950037fcab9a",
  "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation",
  "created": 1663217212,
  "updated": 1663220235,
  "lines": [
    {
      "id": "6322ae3caff09e00006c18a9",
      "text": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217212,
      "updated": 1663217214
    },
    {
      "id": "6322ae3eaff09e00006c18aa",
      "text": ">Vision-Language Pre-training ([VLP]) has advanced the performance for many vision-language tasks. However, most existing pre-trained models only excel in either understanding-based tasks or generation-based tasks. Furthermore, performance improvement has been largely achieved by scaling up the dataset with noisy image-text pairs collected from the web, which is a suboptimal source of supervision. In this paper, we propose BLIP, a new VLP framework which transfers flexibly to both vision-language understanding and generation tasks. BLIP effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. We achieve state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval (+2.7% in average recall@1), image captioning (+2.8% in CIDEr), and VQA (+1.6% in VQA score). BLIP also demonstrates strong generalization ability when directly transferred to video-language tasks in a zero-shot manner. Code, models, and datasets are released at this https URL.",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217214,
      "updated": 1663217251
    },
    {
      "id": "6322ae53aff09e00006c18ab",
      "text": "https://arxiv.org/abs/2201.12086",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217235,
      "updated": 1663217241
    },
    {
      "id": "6322ae59aff09e00006c18ac",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217241,
      "updated": 1663217241
    },
    {
      "id": "6322b8a3aff09e0000d21150",
      "text": "ざっくり言えば",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663219876,
      "updated": 1663219881
    },
    {
      "id": "6322b8a9aff09e0000d21152",
      "text": "　「ネット上の画像とその説明文のペアを収集して学習データに使う」というアプローチは説明文がしばしば適切でないのでノイジー",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663219882,
      "updated": 1663219948
    },
    {
      "id": "6322b8ecaff09e0000d21153",
      "text": "　提案手法ではまず画像から説明文を作り、それとWeb上の説明文を比較して、より良い方を選ぶことで学習データを改善していく",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663219949,
      "updated": 1663220021
    },
    {
      "id": "6322ba09aff09e00006c18af",
      "text": "　\t[https://gyazo.com/e177a0b5e05690359ace08067bd2b328]",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663220234,
      "updated": 1663220235
    },
    {
      "id": "6322ba0baff09e00006c18b0",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663220235,
      "updated": 1663220235
    },
    {
      "id": "6322b935aff09e0000d21154",
      "text": "　Q: どうやって説明文を作るのか",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663220022,
      "updated": 1663220033
    },
    {
      "id": "6322b941aff09e0000d21155",
      "text": "　Q: どうやって「より良い説明文」かを判定するのか",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663220033,
      "updated": 1663220046
    },
    {
      "id": "6322b8a4aff09e0000d21151",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663219876,
      "updated": 1663219876
    },
    {
      "id": "6322ae6faff09e00006c18ad",
      "text": "github: https://github.com/salesforce/BLIP",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217264,
      "updated": 1663217276
    },
    {
      "id": "6322ae7baff09e00006c18ae",
      "text": "",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217276,
      "updated": 1663217276
    },
    {
      "id": "6322ae16886c950037fcab9a",
      "text": "[BLIP]",
      "userId": "582e63d27c56960011aff09e",
      "created": 1663217212,
      "updated": 1663217217
    }
  ]
}